# -*- coding: utf-8 -*-
"""audios_to_text_summary.ipynb

Automatically generated by Colab.

"""

!pip install -q transformers datasets torchaudio librosa

from google.colab import files
uploaded = files.upload()

import torch
import torchaudio
from transformers import WhisperProcessor, WhisperForConditionalGeneration

device = "cuda" if torch.cuda.is_available() else "cpu"

processor = WhisperProcessor.from_pretrained("openai/whisper-small")
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small").to(device)

def transcribe_audio(file_path):
    speech_array, sampling_rate = torchaudio.load(file_path)
    speech_array = torchaudio.functional.resample(speech_array, orig_freq=sampling_rate, new_freq=16000)
    input_features = processor(speech_array.squeeze().numpy(), sampling_rate=16000, return_tensors="pt").input_features.to(device)

    predicted_ids = model.generate(input_features)
    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
    return transcription

# Example
#file_path = list(uploaded.keys())
# transcript = transcribe_audio(f for f in list(uploaded.keys()))
# print("Transcript:", transcript)

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

summ_model_name = "philschmid/bart-large-cnn-samsum"  # or "facebook/bart-large-cnn"
tokenizer = AutoTokenizer.from_pretrained(summ_model_name)
summarizer = AutoModelForSeq2SeqLM.from_pretrained(summ_model_name).to(device)

def summarize_text(text):
    inputs = tokenizer([text], max_length=1024, return_tensors="pt", truncation=True).to(device)
    summary_ids = summarizer.generate(inputs["input_ids"], max_length=200, min_length=20, length_penalty=2.0, num_beams=4)
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

transcripts = []
summaries = []


for file_name in uploaded.keys():
    t = transcribe_audio(file_name)
    s = summarize_text(t)
    print(f"\nChunk Transcript: {t}\nChunk Summary: {s}\n")
    transcripts.append(t)
    summaries.append(s)

full_convo = " ".join(transcripts)
final_summary = summarize_text(full_convo)
print("Final Summary of Full Conversation:\n", final_summary)

